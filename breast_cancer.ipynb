{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "breast_cancer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HskkoqW9MQyl",
        "colab_type": "code",
        "outputId": "4c02941a-a9e0-4021-c427-cb78aa939a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.16.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->scikit-plot) (41.2.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U6GXEfIlmIeY",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "np.random.seed(56)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#import scikitplot as scplot  # I'll use it for clustering based problems"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TAcYyBHLnKu-",
        "colab": {}
      },
      "source": [
        "raw_data = load_breast_cancer()\n",
        "X = raw_data.data\n",
        "Y = raw_data.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kYRmwt5V6Ej",
        "colab_type": "code",
        "outputId": "f932d206-cb1c-4855-c375-6cd43918dae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "raw_data.target_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgxG4my12Evq",
        "colab_type": "code",
        "outputId": "2cc98188-456f-4720-9887-c428da923491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(raw_data.DESCR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry \n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
            "        13 is Radius SE, field 23 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePSLogYisCKc",
        "colab_type": "code",
        "outputId": "1277f2ee-c6ea-4c24-e916-2b06e9fb5bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scaled_data = StandardScaler().fit(X).fit_transform(X)\n",
        "print(scaled_data.shape)\n",
        "X = scaled_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwT3NxMljsNr",
        "colab_type": "code",
        "outputId": "4b5ce4a6-247f-4453-c66f-565a0a6a59d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(X.shape,Y.shape)\n",
        "print(X is scaled_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30) (569,)\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZiNA8kpj1M0",
        "colab_type": "code",
        "outputId": "ebce6a3f-9629-405b-f4aa-b17fd3ef55f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df = pd.DataFrame(X,columns=raw_data.feature_names)\n",
        "df.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.097064</td>\n",
              "      <td>-2.073335</td>\n",
              "      <td>1.269934</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>1.568466</td>\n",
              "      <td>3.283515</td>\n",
              "      <td>2.652874</td>\n",
              "      <td>2.532475</td>\n",
              "      <td>2.217515</td>\n",
              "      <td>2.255747</td>\n",
              "      <td>2.489734</td>\n",
              "      <td>-0.565265</td>\n",
              "      <td>2.833031</td>\n",
              "      <td>2.487578</td>\n",
              "      <td>-0.214002</td>\n",
              "      <td>1.316862</td>\n",
              "      <td>0.724026</td>\n",
              "      <td>0.660820</td>\n",
              "      <td>1.148757</td>\n",
              "      <td>0.907083</td>\n",
              "      <td>1.886690</td>\n",
              "      <td>-1.359293</td>\n",
              "      <td>2.303601</td>\n",
              "      <td>2.001237</td>\n",
              "      <td>1.307686</td>\n",
              "      <td>2.616665</td>\n",
              "      <td>2.109526</td>\n",
              "      <td>2.296076</td>\n",
              "      <td>2.750622</td>\n",
              "      <td>1.937015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.829821</td>\n",
              "      <td>-0.353632</td>\n",
              "      <td>1.685955</td>\n",
              "      <td>1.908708</td>\n",
              "      <td>-0.826962</td>\n",
              "      <td>-0.487072</td>\n",
              "      <td>-0.023846</td>\n",
              "      <td>0.548144</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>-0.868652</td>\n",
              "      <td>0.499255</td>\n",
              "      <td>-0.876244</td>\n",
              "      <td>0.263327</td>\n",
              "      <td>0.742402</td>\n",
              "      <td>-0.605351</td>\n",
              "      <td>-0.692926</td>\n",
              "      <td>-0.440780</td>\n",
              "      <td>0.260162</td>\n",
              "      <td>-0.805450</td>\n",
              "      <td>-0.099444</td>\n",
              "      <td>1.805927</td>\n",
              "      <td>-0.369203</td>\n",
              "      <td>1.535126</td>\n",
              "      <td>1.890489</td>\n",
              "      <td>-0.375612</td>\n",
              "      <td>-0.430444</td>\n",
              "      <td>-0.146749</td>\n",
              "      <td>1.087084</td>\n",
              "      <td>-0.243890</td>\n",
              "      <td>0.281190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.579888</td>\n",
              "      <td>0.456187</td>\n",
              "      <td>1.566503</td>\n",
              "      <td>1.558884</td>\n",
              "      <td>0.942210</td>\n",
              "      <td>1.052926</td>\n",
              "      <td>1.363478</td>\n",
              "      <td>2.037231</td>\n",
              "      <td>0.939685</td>\n",
              "      <td>-0.398008</td>\n",
              "      <td>1.228676</td>\n",
              "      <td>-0.780083</td>\n",
              "      <td>0.850928</td>\n",
              "      <td>1.181336</td>\n",
              "      <td>-0.297005</td>\n",
              "      <td>0.814974</td>\n",
              "      <td>0.213076</td>\n",
              "      <td>1.424827</td>\n",
              "      <td>0.237036</td>\n",
              "      <td>0.293559</td>\n",
              "      <td>1.511870</td>\n",
              "      <td>-0.023974</td>\n",
              "      <td>1.347475</td>\n",
              "      <td>1.456285</td>\n",
              "      <td>0.527407</td>\n",
              "      <td>1.082932</td>\n",
              "      <td>0.854974</td>\n",
              "      <td>1.955000</td>\n",
              "      <td>1.152255</td>\n",
              "      <td>0.201391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0     1.097064     -2.073335  ...        2.750622                 1.937015\n",
              "1     1.829821     -0.353632  ...       -0.243890                 0.281190\n",
              "2     1.579888      0.456187  ...        1.152255                 0.201391\n",
              "\n",
              "[3 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NfUxgGf-HMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z6Ahf8CkMLt",
        "colab_type": "code",
        "outputId": "4a86ae89-8e0e-468f-9ccb-ea4a513c7d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train.shape,X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455, 30) (114, 30) (455,) (114,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liVKt7ANMyHT",
        "colab_type": "text"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwPg1o2dtA86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kf = KFold(n_splits = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OH6qycCar4-H",
        "outputId": "624082f3-b5c6-4100-9d95-7d4a76104549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i,j in kf.split(X_train):\n",
        "    print(\"training_set : \",i)\n",
        "    print(\"test_set : \",j)\n",
        "    print('\\n')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_set :  [ 46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
            "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
            "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
            " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
            " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153\n",
            " 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171\n",
            " 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189\n",
            " 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207\n",
            " 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225\n",
            " 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243\n",
            " 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261\n",
            " 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279\n",
            " 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297\n",
            " 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315\n",
            " 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333\n",
            " 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351\n",
            " 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369\n",
            " 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387\n",
            " 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405\n",
            " 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423\n",
            " 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441\n",
            " 442 443 444 445 446 447 448 449 450 451 452 453 454]\n",
            "test_set :  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
            "\n",
            "\n",
            "training_set :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  92  93  94  95  96  97  98  99\n",
            " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
            " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153\n",
            " 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171\n",
            " 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189\n",
            " 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207\n",
            " 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225\n",
            " 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243\n",
            " 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261\n",
            " 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279\n",
            " 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297\n",
            " 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315\n",
            " 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333\n",
            " 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351\n",
            " 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369\n",
            " 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387\n",
            " 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405\n",
            " 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423\n",
            " 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441\n",
            " 442 443 444 445 446 447 448 449 450 451 452 453 454]\n",
            "test_set :  [46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69\n",
            " 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
            "\n",
            "\n",
            "training_set :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153\n",
            " 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171\n",
            " 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189\n",
            " 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207\n",
            " 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225\n",
            " 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243\n",
            " 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261\n",
            " 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279\n",
            " 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297\n",
            " 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315\n",
            " 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333\n",
            " 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351\n",
            " 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369\n",
            " 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387\n",
            " 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405\n",
            " 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423\n",
            " 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441\n",
            " 442 443 444 445 446 447 448 449 450 451 452 453 454]\n",
            "test_set :  [ 92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
            " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
            " 128 129 130 131 132 133 134 135 136 137]\n",
            "\n",
            "\n",
            "training_set :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 184 185 186 187 188 189\n",
            " 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207\n",
            " 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225\n",
            " 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243\n",
            " 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261\n",
            " 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279\n",
            " 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297\n",
            " 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315\n",
            " 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333\n",
            " 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351\n",
            " 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369\n",
            " 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387\n",
            " 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405\n",
            " 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423\n",
            " 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441\n",
            " 442 443 444 445 446 447 448 449 450 451 452 453 454]\n",
            "test_set :  [138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155\n",
            " 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173\n",
            " 174 175 176 177 178 179 180 181 182 183]\n",
            "\n",
            "\n",
            "training_set :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 230 231 232 233 234 235 236 237 238 239 240 241 242 243\n",
            " 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261\n",
            " 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279\n",
            " 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297\n",
            " 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315\n",
            " 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333\n",
            " 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351\n",
            " 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369\n",
            " 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387\n",
            " 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405\n",
            " 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423\n",
            " 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441\n",
            " 442 443 444 445 446 447 448 449 450 451 452 453 454]\n",
            "test_set :  [184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201\n",
            " 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219\n",
            " 220 221 222 223 224 225 226 227 228 229]\n",
            "\n",
            "\n",
            "training_set :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 275 276 277 278\n",
            " 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296\n",
            " 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314\n",
            " 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332\n",
            " 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350\n",
            " 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368\n",
            " 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386\n",
            " 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404\n",
            " 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422\n",
            " 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440\n",
            " 441 442 443 444 445 446 447 448 449 450 451 452 453 454]\n",
            "test_set :  [230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247\n",
            " 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265\n",
            " 266 267 268 269 270 271 272 273 274]\n",
            "\n",
            "\n",
            "training_set :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 320 321 322 323 324 325 326 327 328 329 330 331 332\n",
            " 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350\n",
            " 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368\n",
            " 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386\n",
            " 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404\n",
            " 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422\n",
            " 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440\n",
            " 441 442 443 444 445 446 447 448 449 450 451 452 453 454]\n",
            "test_set :  [275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292\n",
            " 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310\n",
            " 311 312 313 314 315 316 317 318 319]\n",
            "\n",
            "\n",
            "training_set :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 365 366 367 368\n",
            " 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386\n",
            " 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404\n",
            " 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422\n",
            " 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440\n",
            " 441 442 443 444 445 446 447 448 449 450 451 452 453 454]\n",
            "test_set :  [320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337\n",
            " 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355\n",
            " 356 357 358 359 360 361 362 363 364]\n",
            "\n",
            "\n",
            "training_set :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 410 411 412 413 414 415 416 417 418 419 420 421 422\n",
            " 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440\n",
            " 441 442 443 444 445 446 447 448 449 450 451 452 453 454]\n",
            "test_set :  [365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382\n",
            " 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400\n",
            " 401 402 403 404 405 406 407 408 409]\n",
            "\n",
            "\n",
            "training_set :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409]\n",
            "test_set :  [410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427\n",
            " 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445\n",
            " 446 447 448 449 450 451 452 453 454]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5rqK1eRv_jF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_score_list = []\n",
        "std_dev_list = []\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wZaye0lJs6eH"
      },
      "source": [
        "## RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "spmbNuHMsCpb",
        "outputId": "7b614788-b376-4f2f-bc2b-65297aae40c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "rfc = RandomForestClassifier()\n",
        "cv_score = cross_val_score(rfc, X_train, Y_train, cv=kf, scoring='accuracy')\n",
        "\n",
        "\"\"\"print(\"avg. cv_score\",np.mean(cv_score))\n",
        "print(\"std. dev \",np.std(cv_score))\"\"\"\n",
        "cv_score_list.append(np.mean(cv_score))\n",
        "std_dev_list.append(np.std(cv_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bFuUI5GntbMa"
      },
      "source": [
        "## ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mYr803dun_8B",
        "outputId": "430a7a76-cd15-4fba-a3d2-0d4ec579aa46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "etc = ExtraTreesClassifier()\n",
        "cv_score = cross_val_score(etc, X_train, Y_train, cv=kf, scoring='accuracy')\n",
        "\n",
        "cv_score_list.append(np.mean(cv_score))\n",
        "std_dev_list.append(np.std(cv_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6LEwHUK6tsxQ"
      },
      "source": [
        "## SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u2Pyd9i4tl1N",
        "outputId": "3a2f913d-4519-45b0-f6ae-3388518bcf4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "svm_model = SVC()\n",
        "cv_score = cross_val_score(svm_model, X_train, Y_train, cv=kf, scoring='accuracy')\n",
        "\n",
        "cv_score_list.append(np.mean(cv_score))\n",
        "std_dev_list.append(np.std(cv_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zMf_PzrrvXKT"
      },
      "source": [
        "## LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CRoAB4ezt-Ze",
        "outputId": "c58ef635-1708-4f6d-9213-c9f2757f1761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "lg = LogisticRegression()\n",
        "cv_score = cross_val_score(lg, X_train, Y_train, cv=kf, scoring='accuracy')\n",
        "cv_score_list.append(np.mean(cv_score))\n",
        "std_dev_list.append(np.std(cv_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Demof2PMygiO",
        "colab_type": "code",
        "outputId": "925c4032-85f1-40de-beb3-e87c26d91ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "data = {\n",
        "    'mean_cv_score' : cv_score_list,\n",
        "    'std dev' : std_dev_list\n",
        "}\n",
        "\n",
        "df_model = pd.DataFrame(data,index=['rfc','etc','svm','lg'])\n",
        "df_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_cv_score</th>\n",
              "      <th>std dev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rfc</th>\n",
              "      <td>0.951739</td>\n",
              "      <td>0.021266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>etc</th>\n",
              "      <td>0.951836</td>\n",
              "      <td>0.025172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>0.969469</td>\n",
              "      <td>0.029461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lg</th>\n",
              "      <td>0.975990</td>\n",
              "      <td>0.024683</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean_cv_score   std dev\n",
              "rfc       0.951739  0.021266\n",
              "etc       0.951836  0.025172\n",
              "svm       0.969469  0.029461\n",
              "lg        0.975990  0.024683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zXs3LLzkw0g9"
      },
      "source": [
        "# Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l052R2Jpwilt",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zXOpWuWkxAEn",
        "outputId": "768c4ab4-c5f2-47ae-f6a0-ebca58248873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "compiled_model = VotingClassifier(estimators=[('etc',etc),('lr',lg),('svm',svm_model)],voting='hard')\n",
        "\n",
        "cv_score = cross_val_score(compiled_model, X_train, Y_train, cv=kf, scoring='accuracy')\n",
        "cv_score_list.append(np.mean(cv_score))\n",
        "std_dev_list.append(np.std(cv_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntOFXAt36DDC",
        "colab_type": "code",
        "outputId": "eda47892-a280-40d8-b0df-261f7b9508de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "data = {\n",
        "    'mean_cv_score' : cv_score_list,\n",
        "    'std dev' : std_dev_list\n",
        "}\n",
        "\n",
        "df_model = pd.DataFrame(data,index=['RandomForestClassifier',\n",
        "                                    'ExtraTreesClassifier',\n",
        "                                    'SVC','LogisticRegression',\n",
        "                                    'compiled_model(\"etc\",\"lr\",\"svm\")'])\n",
        "df_model.index.name = 'model'\n",
        "df_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_cv_score</th>\n",
              "      <th>std dev</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.951739</td>\n",
              "      <td>0.021266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.951836</td>\n",
              "      <td>0.025172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.969469</td>\n",
              "      <td>0.029461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.975990</td>\n",
              "      <td>0.024683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compiled_model(\"etc\",\"lr\",\"svm\")</th>\n",
              "      <td>0.980435</td>\n",
              "      <td>0.026536</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  mean_cv_score   std dev\n",
              "model                                                    \n",
              "RandomForestClassifier                 0.951739  0.021266\n",
              "ExtraTreesClassifier                   0.951836  0.025172\n",
              "SVC                                    0.969469  0.029461\n",
              "LogisticRegression                     0.975990  0.024683\n",
              "compiled_model(\"etc\",\"lr\",\"svm\")       0.980435  0.026536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4yLHxQXx49t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stat1 = df_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04pNi_cs_Hq1",
        "colab_type": "code",
        "outputId": "5447883b-d4e1-48ce-aec3-9084dcbd1c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "df_model.index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RandomForestClassifier', 'ExtraTreesClassifier', 'SVC',\n",
              "       'LogisticRegression', 'compiled_model(\"etc\",\"lr\",\"svm\")'],\n",
              "      dtype='object', name='model')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Gj1NaC9jB_",
        "colab_type": "code",
        "outputId": "630f5117-a45e-463f-c0da-f18191a5e8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.barh(df_model.index,cv_score_list,height=0.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAD8CAYAAADwvEc8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE8ODJEnqxPAgSZI6+R8YVRKs0Xfx2gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snR84Tx_n_wA",
        "colab_type": "text"
      },
      "source": [
        "### Stacking yeild maximum accuracy of 98.04 with algorithms ExtratreesClassifier, Logisticregression and svm. \n",
        "Now we'll optimize these models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRcsVAxPmy7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an empty list to store scores of models with their hyperparameters\n",
        "cv_score_list = []\n",
        "std_dev_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf3hFUkDTQ9j",
        "colab_type": "text"
      },
      "source": [
        "## Tuning ExtratreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCxzT2IKCtzv",
        "colab_type": "code",
        "outputId": "93d335c1-012a-4d8e-a2d7-ad94e944dc1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "etc.get_params"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseEstimator.get_params of ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
              "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                     min_samples_leaf=1, min_samples_split=2,\n",
              "                     min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
              "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
              "                     warm_start=False)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYVPr8b0T2Hm",
        "colab_type": "code",
        "outputId": "e39ba84e-f9f1-4442-e1e4-d6621d69dba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# No. of trees in ExtraTreesClassifier\n",
        "n_estimators = [int(x) for x in np.linspace(start=100,stop=500,num=15)]\n",
        "print(n_estimators)\n",
        "\n",
        "# No. of features to consider  at every split\n",
        "max_features = ['auto','sqrt','log2',None]\n",
        "print(max_features)\n",
        "\n",
        "# Maxm no. of levels in tree\n",
        "max_depth = [int(i) for i in np.linspace(start=10,stop=150)]\n",
        "max_depth.append(None)\n",
        "print(max_depth)\n",
        "\n",
        "#Minm no. of samples to split a node\n",
        "min_samples_split=[2,3,4,5,10]\n",
        "\n",
        "# Minm no. of samples required at each leaf node\n",
        "min_samples_leaf = [1,2,4]\n",
        "\n",
        "# methods for selecting samples for traning  each tree\n",
        "bootstrap = [True,False]\n",
        "\n",
        "# create param_grid\n",
        "param_grid = dict(n_estimators = n_estimators,\n",
        "                 max_features = max_features,\n",
        "                 max_depth = max_depth,\n",
        "                 min_samples_split = min_samples_split,\n",
        "                 min_samples_leaf = min_samples_leaf,\n",
        "                 bootstrap = bootstrap)\n",
        "\n",
        "print (param_grid)\n",
        "\n",
        "# cross validation using RandomizedSearchCV\n",
        "rscv =  RandomizedSearchCV(etc,param_grid,cv=kf,scoring='accuracy',random_state=10)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[100, 128, 157, 185, 214, 242, 271, 300, 328, 357, 385, 414, 442, 471, 500]\n",
            "['auto', 'sqrt', 'log2', None]\n",
            "[10, 12, 15, 18, 21, 24, 27, 30, 32, 35, 38, 41, 44, 47, 50, 52, 55, 58, 61, 64, 67, 70, 72, 75, 78, 81, 84, 87, 90, 92, 95, 98, 101, 104, 107, 110, 112, 115, 118, 121, 124, 127, 130, 132, 135, 138, 141, 144, 147, 150, None]\n",
            "{'n_estimators': [100, 128, 157, 185, 214, 242, 271, 300, 328, 357, 385, 414, 442, 471, 500], 'max_features': ['auto', 'sqrt', 'log2', None], 'max_depth': [10, 12, 15, 18, 21, 24, 27, 30, 32, 35, 38, 41, 44, 47, 50, 52, 55, 58, 61, 64, 67, 70, 72, 75, 78, 81, 84, 87, 90, 92, 95, 98, 101, 104, 107, 110, 112, 115, 118, 121, 124, 127, 130, 132, 135, 138, 141, 144, 147, 150, None], 'min_samples_split': [2, 3, 4, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYccO10Xhlyc",
        "colab_type": "code",
        "outputId": "db387ec7-aaa0-42d1-d827-9a31b2d592ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "rscv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
              "                   error_score='raise-deprecating',\n",
              "                   estimator=ExtraTreesClassifier(bootstrap=False,\n",
              "                                                  class_weight=None,\n",
              "                                                  criterion='gini',\n",
              "                                                  max_depth=None,\n",
              "                                                  max_features='auto',\n",
              "                                                  max_leaf_nodes=None,\n",
              "                                                  min_impurity_decrease=0.0,\n",
              "                                                  min_impurity_split=None,\n",
              "                                                  min_samples_leaf=1,\n",
              "                                                  min_samples_split=2,\n",
              "                                                  min_weight_fraction...\n",
              "                                                      27, 30, 32, 35, 38, 41,\n",
              "                                                      44, 47, 50, 52, 55, 58,\n",
              "                                                      61, 64, 67, 70, 72, 75,\n",
              "                                                      78, 81, 84, 87, 90, 92, ...],\n",
              "                                        'max_features': ['auto', 'sqrt', 'log2',\n",
              "                                                         None],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 3, 4, 5, 10],\n",
              "                                        'n_estimators': [100, 128, 157, 185,\n",
              "                                                         214, 242, 271, 300,\n",
              "                                                         328, 357, 385, 414,\n",
              "                                                         442, 471, 500]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=10, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcyWzGuJidEj",
        "colab_type": "code",
        "outputId": "feddff47-3580-4660-9def-15ffffc81a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "rscv.fit(X_train,Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
              "                   error_score='raise-deprecating',\n",
              "                   estimator=ExtraTreesClassifier(bootstrap=False,\n",
              "                                                  class_weight=None,\n",
              "                                                  criterion='gini',\n",
              "                                                  max_depth=None,\n",
              "                                                  max_features='auto',\n",
              "                                                  max_leaf_nodes=None,\n",
              "                                                  min_impurity_decrease=0.0,\n",
              "                                                  min_impurity_split=None,\n",
              "                                                  min_samples_leaf=1,\n",
              "                                                  min_samples_split=2,\n",
              "                                                  min_weight_fraction...\n",
              "                                                      27, 30, 32, 35, 38, 41,\n",
              "                                                      44, 47, 50, 52, 55, 58,\n",
              "                                                      61, 64, 67, 70, 72, 75,\n",
              "                                                      78, 81, 84, 87, 90, 92, ...],\n",
              "                                        'max_features': ['auto', 'sqrt', 'log2',\n",
              "                                                         None],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 3, 4, 5, 10],\n",
              "                                        'n_estimators': [100, 128, 157, 185,\n",
              "                                                         214, 242, 271, 300,\n",
              "                                                         328, 357, 385, 414,\n",
              "                                                         442, 471, 500]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=10, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YYkIt1pirC6",
        "colab_type": "code",
        "outputId": "c2e1bea0-f1d9-4cfc-92d1-968e0e68d6be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "rscv.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': 144,\n",
              " 'max_features': None,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 3,\n",
              " 'n_estimators': 442}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Eiy7Ub1i2MF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "etc2 = ExtraTreesClassifier(n_estimators=442,max_depth=144,\n",
        "                          max_features=None,min_samples_leaf=1,\n",
        "                          min_samples_split=3,\n",
        "                          bootstrap = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf3DdZFIi2H1",
        "colab_type": "code",
        "outputId": "fa530890-9c52-4e31-f57c-1d707b01d9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cv_score = cross_val_score(etc2,X_train,Y_train,cv=kf)\n",
        "print(np.mean(cv_score))\n",
        "cv_score_list.append(np.mean(cv_score))\n",
        "std_dev_list.append(np.std(cv_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9759420289855072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwvXiAGPluGj",
        "colab_type": "text"
      },
      "source": [
        "## Tuning LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWsXWZOji2BG",
        "colab_type": "code",
        "outputId": "62815a00-8aca-46fd-d069-898faa5f0d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "lg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwlFBJwPi18L",
        "colab_type": "code",
        "outputId": "aa2678fd-6a7a-4608-f223-1e375eccceae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# specify the norm used for penalization\n",
        "penalty = ['l1']\n",
        "\n",
        "C = [float(1*10**i) for i in range(-3,4)]\n",
        "print(C)\n",
        "\n",
        "fit_intercept = [True,False]\n",
        "\n",
        "solver = ['liblinear', 'saga']\n",
        "\n",
        "warm_state = [True,False]\n",
        "\n",
        "dual = [True,False]\n",
        "\n",
        "# create grid\n",
        "param_grid = dict(C = C, penalty = penalty,\n",
        "                 fit_intercept = fit_intercept,\n",
        "                 solver = solver)\n",
        "# cross validation using RandomizedSearchCV\n",
        "rscv =  RandomizedSearchCV(lg,param_grid,cv=kf,scoring='accuracy',random_state=10)\n",
        "\n",
        "rscv.fit(X_train,Y_train)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
              "                   error_score='raise-deprecating',\n",
              "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                dual=False, fit_intercept=True,\n",
              "                                                intercept_scaling=1,\n",
              "                                                l1_ratio=None, max_iter=100,\n",
              "                                                multi_class='warn', n_jobs=None,\n",
              "                                                penalty='l2', random_state=None,\n",
              "                                                solver='warn', tol=0.0001,\n",
              "                                                verbose=0, warm_start=False),\n",
              "                   iid='warn', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'C': [0.001, 0.01, 0.1, 1.0, 10.0,\n",
              "                                              100.0, 1000.0],\n",
              "                                        'fit_intercept': [True, False],\n",
              "                                        'penalty': ['l1'],\n",
              "                                        'solver': ['liblinear', 'saga']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=10, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21MBZxk9MUuy",
        "colab_type": "code",
        "outputId": "16be66f2-f772-4833-cff3-fad3e5fda669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rscv.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.1, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'saga'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifq2e-cYMUpM",
        "colab_type": "code",
        "outputId": "4f14cb7c-a85c-489b-ff8b-4aacb1fd5768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "lg2 = LogisticRegression(C=1.0,fit_intercept=False,penalty='l1',solver='saga')\n",
        "cv_score = cross_val_score(lg2,X_train,Y_train,cv=kf)\n",
        "print(np.mean(cv_score))\n",
        "cv_score_list.append(np.mean(cv_score))\n",
        "std_dev_list.append(np.std(cv_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9803381642512077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nPIbIjhHTwbD"
      },
      "source": [
        "# # Tuning SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PTTQOHAoTwCW",
        "outputId": "6d91479f-8015-4d82-aaf0-a4eac8b3d423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "svm_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LXQTSEeJa4-z",
        "outputId": "3912693d-eb06-4b57-efab-6d797f7d9f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "C = [float(1*10**i) for i in range(-3,4)]\n",
        "class_weight = ['balanced',None]\n",
        "decision_function_shape = [ 'ovo', 'ovr']\n",
        "kernel = ['rbf','poly','linear']\n",
        "degree = [int(x) for x in range(1,5)]\n",
        "gamma = ['scale','auto_deprecated']\n",
        "probability = [True,False]\n",
        "shrinking = [True,False]\n",
        "tol = [float(1*10**i) for i in range(-5,4)]\n",
        "print(tol)\n",
        "verbose = [True,False]\n",
        "\n",
        "# create grid\n",
        "param_grid = dict(C = C,\n",
        "                 class_weight = class_weight,\n",
        "                 decision_function_shape = decision_function_shape,\n",
        "                 kernel = kernel,\n",
        "                 degree = degree,\n",
        "                 gamma = gamma,\n",
        "                 probability = probability,\n",
        "                 shrinking = shrinking,\n",
        "                 tol = tol,\n",
        "                 verbose = verbose)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oKeo9h0tbB7D",
        "colab": {}
      },
      "source": [
        "rscv = RandomizedSearchCV(svm_model,param_grid,cv=kf,random_state=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZBrghQp-HQG",
        "colab_type": "code",
        "outputId": "c44be1da-f692-403b-86e2-eee5e7ec9ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rscv.fit(X_train,Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
              "                   error_score='raise-deprecating',\n",
              "                   estimator=SVC(C=1.0, cache_size=200, class_weight=None,\n",
              "                                 coef0=0.0, decision_function_shape='ovr',\n",
              "                                 degree=3, gamma='auto_deprecated',\n",
              "                                 kernel='rbf', max_iter=-1, probability=False,\n",
              "                                 random_state=None, shrinking=True, tol=0.001,\n",
              "                                 verbose=False),\n",
              "                   iid='warn', n_iter=...\n",
              "                                        'decision_function_shape': ['ovo',\n",
              "                                                                    'ovr'],\n",
              "                                        'degree': [1, 2, 3, 4],\n",
              "                                        'gamma': ['scale', 'auto_deprecated'],\n",
              "                                        'kernel': ['rbf', 'poly', 'linear'],\n",
              "                                        'probability': [True, False],\n",
              "                                        'shrinking': [True, False],\n",
              "                                        'tol': [1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
              "                                                1.0, 10.0, 100.0, 1000.0],\n",
              "                                        'verbose': [True, False]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=10, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7iA2wGo-HQS",
        "colab_type": "code",
        "outputId": "ba881b18-129e-4d53-d45a-d77ccbe3f042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "rscv.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 100.0,\n",
              " 'class_weight': None,\n",
              " 'decision_function_shape': 'ovr',\n",
              " 'degree': 1,\n",
              " 'gamma': 'auto_deprecated',\n",
              " 'kernel': 'poly',\n",
              " 'probability': True,\n",
              " 'shrinking': False,\n",
              " 'tol': 0.1,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcCzxJJfm1r2",
        "colab_type": "code",
        "outputId": "25912615-39e5-44e4-ba7b-751e3fea8074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "svm_model2 = SVC(C=100.0,tol=0.1,kernel='poly',gamma='auto_deprecated',\n",
        "               decision_function_shape='ovr',degree=1,class_weight=None,\n",
        "               probability=True,shrinking=False,verbose=False)\n",
        "\n",
        "cv_score = cross_val_score(svm_model2,X_train,Y_train,cv=kf)\n",
        "print(np.mean(cv_score))\n",
        "cv_score_list.append(np.mean(cv_score))\n",
        "std_dev_list.append(np.std(cv_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9760386473429952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDW-dZoHdqfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV6uQxXRi4IS",
        "colab_type": "text"
      },
      "source": [
        "### Now compile above models with their own hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nb_LoRkdqaq",
        "colab_type": "code",
        "outputId": "be6332be-ca50-4812-9b11-cabbefab165a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        }
      },
      "source": [
        "compiled_model2 = VotingClassifier(estimators=[('etc',etc2),('svm',svm_model2),('lg',lg2)],voting='hard')\n",
        "\n",
        "cv_score = cross_val_score(compiled_model2, X_train, Y_train, cv=kf, scoring='accuracy')\n",
        "print(np.mean(cv_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9825603864734299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHOirMHvdqWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_score_list.append(np.mean(cv_score))\n",
        "std_dev_list.append(np.std(cv_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0rAq2tCdqPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# presenting performance of model in tabular form\n",
        "data = {\n",
        "    'mean_cv_score' : cv_score_list,\n",
        "    'std dev' : std_dev_list\n",
        "}\n",
        "\n",
        "df_model = pd.DataFrame(data,index=[\n",
        "                                    'ExtraTreesClassifier',\n",
        "                                    'SVC','LogisticRegression',\n",
        "                                    'compiled_model(\"etc\",\"lr\",\"svm\")'])\n",
        "df_model.index.name = 'model'\n",
        "stat2 = df_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbhyV9Thdplj",
        "colab_type": "code",
        "outputId": "db5a1bb6-c0de-48c2-9df0-ccdc1e2a38c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "\n",
        "stat1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_cv_score</th>\n",
              "      <th>std dev</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.951739</td>\n",
              "      <td>0.021266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.951836</td>\n",
              "      <td>0.025172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.969469</td>\n",
              "      <td>0.029461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.975990</td>\n",
              "      <td>0.024683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compiled_model(\"etc\",\"lr\",\"svm\")</th>\n",
              "      <td>0.980435</td>\n",
              "      <td>0.026536</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  mean_cv_score   std dev\n",
              "model                                                    \n",
              "RandomForestClassifier                 0.951739  0.021266\n",
              "ExtraTreesClassifier                   0.951836  0.025172\n",
              "SVC                                    0.969469  0.029461\n",
              "LogisticRegression                     0.975990  0.024683\n",
              "compiled_model(\"etc\",\"lr\",\"svm\")       0.980435  0.026536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdxoziuVyHfG",
        "colab_type": "code",
        "outputId": "335c5c40-b86a-4347-9e42-af6fdc67d9d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "stat2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_cv_score</th>\n",
              "      <th>std dev</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.975942</td>\n",
              "      <td>0.020494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.980338</td>\n",
              "      <td>0.022706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.976039</td>\n",
              "      <td>0.029883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compiled_model(\"etc\",\"lr\",\"svm\")</th>\n",
              "      <td>0.982560</td>\n",
              "      <td>0.023423</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  mean_cv_score   std dev\n",
              "model                                                    \n",
              "ExtraTreesClassifier                   0.975942  0.020494\n",
              "SVC                                    0.980338  0.022706\n",
              "LogisticRegression                     0.976039  0.029883\n",
              "compiled_model(\"etc\",\"lr\",\"svm\")       0.982560  0.023423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tt4x0lhy0Pc",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dRsDIJN0MDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y =[],[]\n",
        "etc2.fit(X_train,Y_train)\n",
        "f = list(zip(raw_data.feature_names,etc2.feature_importances_))\n",
        "k  = lambda s: s[1]\n",
        "f = sorted(f,key=k,reverse=True)\n",
        "for i,j in f:\n",
        "  y.append(i)\n",
        "  x.append(j)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgq20R_O43Il",
        "colab_type": "code",
        "outputId": "c2be3933-6040-43ec-b199-d1d2af5a3f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"feature Importance\")\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.barh(y,x,height=.3,color='r')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+IAAAHwCAYAAAAim9XyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH1t2R10y6fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JT1eAary6ZL",
        "colab_type": "code",
        "outputId": "7b6788b8-1a2c-4946-afcc-6c965635b5f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        }
      },
      "source": [
        "\n",
        "feature_col = [i for i,j in f[:10]] \n",
        "d = dict().fromkeys(feature_col)\n",
        "for i in list(d.keys()):\n",
        "  d[i] = df[i]\n",
        "df2 = pd.DataFrame(d)\n",
        "print(df2.shape)\n",
        "df2.head()\n",
        "\n",
        "X_new = df[feature_col]\n",
        "X_new.head()\n",
        "X.shape\n",
        "print(X_new.shape)\n",
        "X_train,X_test, Y_train, Y_test = train_test_split(X_new,Y,test_size=0.2)\n",
        "cv_score = cross_val_score(compiled_model2,X_train,Y_train,cv=kf)\n",
        "print(np.mean(cv_score))\n",
        "print(np.mean(cv_score))\n",
        "compiled_model2.fit(X_train,Y_train,)\n",
        "y_pred = compiled_model2.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 10)\n",
            "(569, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.962657004830918\n",
            "0.962657004830918\n",
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JavEM8SuAX9M",
        "colab_type": "code",
        "outputId": "f15e5223-c37f-442a-8df1-12bb32e9bbcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(accuracy_score(Y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71KDbkOpBwcJ",
        "colab_type": "text"
      },
      "source": [
        "## Result Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_POR1AuBzVc",
        "colab_type": "text"
      },
      "source": [
        "\\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UflCecGB7L1",
        "colab_type": "code",
        "outputId": "a7aba163-de6b-4603-c02b-7ac87748edce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "Y = pd.DataFrame(Y)\n",
        "Y.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    569\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Qn5dz7CCcE",
        "colab_type": "code",
        "outputId": "facbc3dd-0eda-4736-e185-e81b4dc9b8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "isof = IsolationForest().fit(X_train).pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
            "  \" be removed in 0.22.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGmdkAX9CN22",
        "colab_type": "code",
        "outputId": "4e5618fd-e6cb-4fbb-970e-3b7ddc5f1689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1, -1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1, -1,  1,\n",
              "        1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
              "        1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
              "        1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1, -1,  1,  1,  1,  1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1, -1,  1,  1,  1, -1,  1,  1, -1,  1, -1, -1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "       -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
              "        1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,\n",
              "        1,  1,  1,  1, -1, -1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1, -1,  1,  1,  1, -1, -1,  1,  1,  1,  1, -1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEdCzy__tO9E",
        "colab_type": "text"
      },
      "source": [
        "# Accuracy = 99.12%\n",
        "Selecting the 22 most relative important feautures for the model yeilded accuracy of 99.12%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaZZVUcm-HRC",
        "colab_type": "text"
      },
      "source": [
        "# Classification  Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LHhZ6D_-HRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F88mawd5-HRK",
        "colab_type": "code",
        "outputId": "7cc86924-aae1-49bb-a0da-fa46e007ccec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "matrix = confusion_matrix(Y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[40  0]\n",
            " [ 0 74]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oidwfUv-HRR",
        "colab_type": "code",
        "outputId": "b6cb7584-6166-425f-e791-bfb9fc2b36bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(\"TP: \",matrix[1,1]) # sama as matrix[1][1]\n",
        "print(\"TN: \",matrix[0,0])\n",
        "print(\"FP: \",matrix[0,1])\n",
        "print(\"FN: \",matrix[1,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP:  74\n",
            "TN:  40\n",
            "FP:  0\n",
            "FN:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BFgWJbL-HRY",
        "colab_type": "code",
        "outputId": "e4944a11-8581-4ecf-9936-822538dae977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Detecting the False Positive values\n",
        "# compare Y_test and y_pred\n",
        "\n",
        "total = 0\n",
        "for i,j in enumerate(Y_test):\n",
        "    if Y_test[i] != y_pred[i]:\n",
        "        total+=1\n",
        "        print(\"index : \",i)\n",
        "print('no. of false predictions =',total)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of false predictions = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCtMrKcvfi7P",
        "colab_type": "text"
      },
      "source": [
        "## Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iVGT9nU-HRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm8Y2UdYzjTw",
        "colab_type": "code",
        "outputId": "081c6166-706d-49c1-99cb-2fd6075e3a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(classification_report(Y_test,y_pred,target_names=raw_data.target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       1.00      1.00      1.00        40\n",
            "      benign       1.00      1.00      1.00        74\n",
            "\n",
            "    accuracy                           1.00       114\n",
            "   macro avg       1.00      1.00      1.00       114\n",
            "weighted avg       1.00      1.00      1.00       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr0CaoGkrlrh",
        "colab_type": "text"
      },
      "source": [
        "#### Serialization using pickle\n",
        "Serialization means converting a object into stream of bytes so to recover the object if it is get lost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38n8mD3TK-z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLoT2ExALFXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(compiled_model2,file=open('BC_detection.pkl','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSmpRISsLOV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BC_model = pickle.load(file=open('BC_detection.pkl','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mr6DnHes5HP",
        "colab_type": "code",
        "outputId": "b8060af3-43e9-4a76-b74c-10ef9c9ee905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "BC_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('etc',\n",
              "                              ExtraTreesClassifier(bootstrap=True,\n",
              "                                                   class_weight=None,\n",
              "                                                   criterion='gini',\n",
              "                                                   max_depth=144,\n",
              "                                                   max_features=None,\n",
              "                                                   max_leaf_nodes=None,\n",
              "                                                   min_impurity_decrease=0.0,\n",
              "                                                   min_impurity_split=None,\n",
              "                                                   min_samples_leaf=1,\n",
              "                                                   min_samples_split=3,\n",
              "                                                   min_weight_fraction_leaf=0.0,\n",
              "                                                   n_estimators=442,\n",
              "                                                   n_jobs=None, oob_score=False,\n",
              "                                                   random_state=None, verbose=0,...\n",
              "                                  random_state=None, shrinking=False, tol=0.1,\n",
              "                                  verbose=False)),\n",
              "                             ('lg',\n",
              "                              LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                 dual=False,\n",
              "                                                 fit_intercept=False,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=100,\n",
              "                                                 multi_class='warn',\n",
              "                                                 n_jobs=None, penalty='l1',\n",
              "                                                 random_state=None,\n",
              "                                                 solver='saga', tol=0.0001,\n",
              "                                                 verbose=0,\n",
              "                                                 warm_start=False))],\n",
              "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2_HIBLgqtp7",
        "colab_type": "text"
      },
      "source": [
        "# Thank you"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi8Z2eZFvIGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}